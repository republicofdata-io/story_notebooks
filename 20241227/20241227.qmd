---
title: "The Journey of a Conversation on the Climate Resilience Data Platform"
format:
  html:
    code-fold: true
jupyter: python3
---

We've iterated quickly over the past months to put together a platform that captures climate-related conversations on social networks. We shared our journey and turned a blind eye on the tech debt we accumulated. Or didn't blink twice when confronted with suspicious data quality.

The last months might not have led to any breakthrough innovation worth reporting on, but we have been busy. Refactoring our asset's management system, enforcing stricer typed datasets, productionizing AI agents, and more.

Now that we're on the eve of using this platform to publish new editions of the Climate Narratives Report, it's time to take a step back, and look at the output.

::: {.callout-note}
At [RepublicOfData.io](https://republicofdata.io), we openly share our code and journey. Here's a list of repositories that are part of this project:

- [Climate Resilience Data Platform](https://github.com/republicofdata-io/climate_resilience): the data platform itself.
- [Story notebooks](https://github.com/republicofdata-io/story_notebooks): the notebooks to interact with the data.
- [Damn Tool](https://github.com/republicofdata-io/damn): a tool to interact with the platform's assets.
:::

## üèõÔ∏è Design
![](climate_narratives_dag.png)

## üìä Data Assets
Let's start by listing the data assets we have on the platform. 

```{python}
import json
from damn_tool.ls import list_assets

result = list_assets(configs_dir="../.damn/")
data = json.loads(result)

organized_data = {}
for item in data["ls"]:
    product, key = item.split("/", 1)
    if product not in organized_data:
        organized_data[product] = []
    organized_data[product].append(key)

for product, keys in organized_data.items():
    print(f"{product}:")
    for key in keys:
        print(f" - {key}")
```

We have 4 key data products:

- `media`: The climate-related articles we source.
- `social_networks`: The conversations that refer to the articles above.
- `narratives`: The classification of conversations and posts into discourse types and narratives.
- `analytics`: The dimensional representation of those asset for reporting purposes.

### Media Assets
Let's now get some details on our media assets.

```{python}
from damn_tool.show import show_asset

result = show_asset('media/nytimes_articles', configs_dir="../.damn/")
data = json.loads(result)

print(json.dumps(data, indent=4))
```

And some metrics:
```{python}
from damn_tool.metrics import asset_metrics

result = asset_metrics('media/nytimes_articles', configs_dir="../.damn/")
data = json.loads(result)

print(json.dumps(data, indent=4))
```

Let's now pull a sample of data from this asset:

```{python}
import pandas as pd
from google.cloud import bigquery

# Construct a BigQuery client object.
client = bigquery.Client()

# TODO: Set your query here
query = """
    select * from `phonic-biplane-420020.media.nytimes_articles`
    order by published_ts desc
    limit 5"""

# Make an API request.
query_job = client.query(query)

# Wait for the job to complete.
articles_df = query_job.result().to_dataframe()
articles_df
```


